{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev Setups: Connecting Python and SQL (Linux version)\n",
    "\n",
    "The purpose of this IPython notebook is to demonstrate the usefulness of connecting python to a relational database by using a python toolkit called SQLAlchemy. This tutorial follows the previous document, *** Testing Python and Data Science basic stack ***\n",
    "\n",
    "**This notebook provides Linux specific instructions. Updated 8/18**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First off, what is a relational database?\n",
    "\n",
    "Basically, it is a way to store information such that information can be retrieved from it.\n",
    "\n",
    "MySQL and PostgreSQL are examples of relational databases.  For the purposes of an Insight project, you can use either one.\n",
    "\n",
    "Why would you use a relational database instead of a csv or two?\n",
    "\n",
    "**A few reasons:**\n",
    "\n",
    "- They scale easily\n",
    "\n",
    "-  They are easy to query\n",
    "\n",
    "- Itâ€™s possible to do transactions in those cases where you need to write to a database, not just read from it\n",
    "\n",
    "- Everyone in industry uses them, so you should get familiar with them, too.\n",
    "\n",
    "***What does a relational database look like? ***\n",
    "\n",
    "We can take a look.  First we need to set up a few things. The first thing we want to do is to get a PostgreSQL server up and running.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postgres Linux installation\n",
    "These instructions have been tested for installing Postgres 9.6 on Ubuntu 16.04.\n",
    "\n",
    "Check out this [post](https://askubuntu.com/questions/831292/how-to-install-postgresql-9-6-on-any-ubuntu-version). This is for installing version 9.6, which should be fine for our purposes. Run the following series of commands in the terminal (Note: for Ubuntu 18.04, you should only need the first and last commands below):\n",
    "\n",
    "    sudo add-apt-repository \"deb http://apt.postgresql.org/pub/repos/apt/ xenial-pgdg main\"\n",
    "    wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -\n",
    "    sudo apt-get update\n",
    "    sudo username = 'postgres'\n",
    "    sudo apt-get install postgresql-9.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postgres 9.6 should now be installed. Start the service.  \n",
    "\n",
    "    sudo service postgresql start\n",
    "    \n",
    "You can always check that the service is running by: \n",
    "\n",
    "    sudo service postgresql status\n",
    "    \n",
    "Set Unix password for user `postgres`\n",
    "\n",
    "    sudo passwd postgres\n",
    "\n",
    "Set the super user to `postgres`.\n",
    "\n",
    "    su postgres\n",
    "    \n",
    "You can now launch the Postgres interactivate terminal `psql`, where you'll enter as user `postgres`.\n",
    "\n",
    "    psql\n",
    "    \n",
    "Inside `psql`, a list of users can be accessed by running the query:\n",
    "\n",
    "    SELECT username FROM pg_user;\n",
    " \n",
    "Set the password for user `postgres`.\n",
    "\n",
    "    \\password postgres\n",
    "    \n",
    "To exit the terminal:\n",
    "\n",
    "    \\q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll come back to PostgreSQL in a moment. First, we'll set up SQLAlchemy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='python'></a>\n",
    "## Install and load python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside your conda environment, install the necessary packages for python to talk to a sql database.\n",
    "\n",
    "    conda install sqlalchemy psycopg2  \n",
    "    pip3 install sqlalchemy_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a database name (we're using a dataset on births, so we'll call it birth_db)\n",
    "# Set your postgres username/password, and connection specifics\n",
    "username = 'postgres'\n",
    "password = 'my_password'     # change this\n",
    "host     = 'localhost'\n",
    "port     = '5432'            # default port that postgres listens on\n",
    "db_name  = 'birth_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'engine' is a connection to a database\n",
    "## Here, we're using postgres, but sqlalchemy can connect to other things too.\n",
    "engine = create_engine( 'postgresql://{}:{}@{}:{}/{}'.format(username, password, host, port, db_name) )\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a database (if it doesn't exist)\n",
    "if not database_exists(engine.url):\n",
    "    create_database(engine.url)\n",
    "print(database_exists(engine.url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a database from CSV and load it into a pandas dataframe\n",
    "birth_data = pd.read_csv('births2012_downsampled.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert data into database from Python (proof of concept - this won't be useful for big data, of course)\n",
    "birth_data.to_sql('birth_data_table', engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line (to_sql) is doing a lot of heavy lifting.  It's reading a dataframe, it's creating a table, and adding the data to the table.  So ** SQLAlchemy is quite useful! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PostgresSQL without Python\n",
    "\n",
    "As the postgres super user and enter the postgres terminal.\n",
    "\n",
    "    su postgres\n",
    "    psql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Connect to the \"birth_db\" database we created**\n",
    "\n",
    "    \\c birth_db\n",
    "\n",
    "**You should see something like the following**\n",
    "\n",
    "`You are now connected to database \"birth_db\" as user \"postgres\".`\n",
    "\n",
    "\n",
    "**Then try the following query:**\n",
    "\n",
    "    SELECT * FROM birth_data_table;\n",
    "    \n",
    "Note that the semi-colon indicates an end-of-statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can see the table we created!  But it's kinda ugly and hard to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try a few other sample queries.  Before you type in each one, ask yourself what you think the output will look like:\n",
    "\n",
    "`SELECT * FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(infant_sex) FROM birth_data_table WHERE infant_sex='M';`\n",
    "\n",
    "`SELECT COUNT(gestation_weeks), infant_sex FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks, infant_sex;`\n",
    "\n",
    "`SELECT gestation_weeks, COUNT(gestation_weeks) FROM birth_data_table WHERE infant_sex = 'M' GROUP BY gestation_weeks;`\n",
    "\n",
    "All the above queries run, but they are difficult to visually inspect in the Postgres terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with PostgreSQL in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to make queries using psycopg2\n",
    "con = None\n",
    "con = psycopg2.connect(database = db_name, user = username, host = host, password = password )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you have trouble with the command above, make sure host is pointing to '/var/run/postgresql' and not tmp. If you're still having trouble, you may need to change the permissions in pg_hba.conf from peer to trust. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query:\n",
    "sql_query = \"\"\"\n",
    "SELECT * FROM birth_data_table WHERE delivery_method='Cesarean';\n",
    "\"\"\"\n",
    "birth_data_from_sql = pd.read_sql_query(sql_query,con)\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data has been pulled into python, we can leverage pandas methods to work with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "birth_data_from_sql.hist(column='birth_weight');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is reading from a SQL database faster than from a Pandas dataframe?  Probably not for the amount of data you can fit on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(sql_query, con):\n",
    "    data = pd.read_sql_query(sql_query, con)\n",
    "    return data\n",
    "\n",
    "%timeit get_data(sql_query, con)\n",
    "\n",
    "birth_data_from_sql = get_data(sql_query, con)\n",
    "birth_data_from_sql.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pandas_data(df, col, value):\n",
    "    sub_df = df.loc[(df[col] == value)]\n",
    "    return sub_df\n",
    "\n",
    "%timeit get_pandas_data(birth_data, 'delivery_method', 'Cesarean')\n",
    "\n",
    "birth_data_out = get_pandas_data(birth_data, 'delivery_method', 'Cesarean')\n",
    "birth_data_out.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should have given you a quick taste of how to use SQLALchemy, as well as how to run a few SQL queries both at the command line and in python.  You can see that `pandas` is actually a quite a bit faster than PostgreSQL here. This is because we're working with quite a small database (2716 rows Ã— 37 columns), and there is an overhead of time it takes to communicate between python and PostGreSQL.  But as your database gets bigger (and certainly when it's too large to store in memory), working with relational databases becomes a necessity.\n",
    "\n",
    "#### Congrats! You now have Python and SQL ready to go!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
